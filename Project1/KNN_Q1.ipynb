{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9013541e",
   "metadata": {},
   "source": [
    "# Question: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f71e7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.6530190426733' '72.871146648479' '24' 'W']\n",
      " ['1.6471384909498' '72.612785314988' '34' 'W']\n",
      " ['1.6472055785348' '73.53968351051' '33' 'M']\n",
      " ['1.7323008914951' '76.067870338779' '30' 'M']\n",
      " ['1.6750702657911' '81.05582111533' '30' 'M']\n",
      " ['1.5780970716644' '64.926084680188' '30' 'W']\n",
      " ['1.6587629355524' '69.38092449041' '30' 'M']\n",
      " ['1.6763295980234' '77.062295990149' '31' 'M']\n",
      " ['1.7187224085504' '62.112923317057' '37' 'W']\n",
      " ['1.5202218226439' '66.151444019603' '27' 'W']\n",
      " ['1.5552689261884' '66.076386143769' '31' 'W']\n",
      " ['1.6969333189258' '77.45386244568' '34' 'M']\n",
      " ['1.6887980792886' '76.489640732464' '37' 'M']\n",
      " ['1.5213552893624' '63.952944947832' '35' 'W']]\n",
      "[['1.62065758929' '59.376557437583' '32']\n",
      " ['1.7793983848363' '72.071775670801' '36']\n",
      " ['1.7004576585974' '66.267508112786' '31']\n",
      " ['1.6591086215159' '61.751621901787' '29']]\n"
     ]
    }
   ],
   "source": [
    "# Read and load the data\n",
    "import numpy as np\n",
    "\n",
    "def d_cleaning(line):\n",
    "    return line.replace('(', '').replace(')', '').replace(' ', '').strip().split(',')\n",
    "\n",
    "def d_fetching(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        d_input = f.readlines()\n",
    "        clean_input = list(map(d_cleaning, d_input))\n",
    "        f.close()\n",
    "    return clean_input\n",
    "\n",
    "def f_reading(dataset_path):\n",
    "    d_input = d_fetching(dataset_path)\n",
    "    input_np = np.array(d_input)\n",
    "    return input_np\n",
    "\n",
    "d_training = './dataset/1a_2a-training.txt'\n",
    "d_testing = './dataset/1a_2a-test.txt'\n",
    "d_large_120 = './dataset/1cd_2cd-data.txt'\n",
    "\n",
    "tp_train = f_reading(d_training)\n",
    "print(tp_train)\n",
    "tp_test = f_reading(d_testing)\n",
    "print(tp_test)\n",
    "tp_large = f_reading(d_large_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "df9137c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "train_X = []\n",
    "for i in range(tp_train.shape[0]):\n",
    "    train_X.append(np.array(tp_train[i][:-1], dtype=np.float32))\n",
    "train_X = np.array(train_X)\n",
    "\n",
    "test_X = np.array(tp_test, dtype=np.float32)\n",
    "    \n",
    "large_X = []\n",
    "for i in range(tp_large.shape[0]):\n",
    "    large_X.append(np.array(tp_large[i][:-1], dtype=np.float32))\n",
    "large_X = np.array(large_X)\n",
    "    \n",
    "train_Y = []\n",
    "for i in range(tp_train.shape[0]):\n",
    "    train_Y.append([tp_train[i][-1]])\n",
    "train_Y = np.array(train_Y, dtype=object)\n",
    "\n",
    "large_Y = []\n",
    "for i in range(tp_large.shape[0]):\n",
    "    large_Y.append([tp_large[i][-1]])\n",
    "large_Y = np.array(large_Y, dtype=object)\n",
    "\n",
    "data_train = np.concatenate((train_X, train_Y), axis=1)\n",
    "data_large = np.concatenate((large_X, large_Y), axis=1)\n",
    "data_test = np.concatenate((test_X, np.empty((test_X.shape[0],1), dtype=object)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9388b",
   "metadata": {},
   "source": [
    "# Part a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "23d6b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartesian distance\n",
    "import math\n",
    "\n",
    "def cartesian_distance(x, y):\n",
    "    dist = 0\n",
    "    \n",
    "    # Calculate Cartesian distance\n",
    "    for d in range(len(x)-1):\n",
    "        dist += (x[d] - y[d])**2\n",
    "        \n",
    "    dist = math.sqrt(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5ac87a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan distance\n",
    "def manhattan_distance(x, y):\n",
    "    dist = 0\n",
    "    \n",
    "    # Calculate Manhattan distance\n",
    "    for d in range(len(x)-1):\n",
    "        dist += abs(x[d] - y[d])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c31751e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minkowski distance\n",
    "def minkowski_distance(x, y, order=3):\n",
    "    dist= 0\n",
    "    \n",
    "    # Calculate minkowski distance using order\n",
    "    for d in range(len(x)-1):\n",
    "        dist += abs(x[d] - y[d])**order\n",
    "        \n",
    "    dist = dist**(1/order)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b5566819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def select_neighbors(train, row_testing, num_neighbors, dist_type):\n",
    "    dist_values= list()\n",
    "    for row_training in train:\n",
    "        dist = dist_type(row_testing, row_training)\n",
    "        dist_values.append((row_training, dist))\n",
    "    dist_values.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(dist_values[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2fa05860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification prediction with neighbors\n",
    "def predict(train, test, num_neighbors, dist_type):\n",
    "    l_predictions = []\n",
    "    for row_testing in test:\n",
    "        neighbors = select_neighbors(train, row_testing, num_neighbors, dist_type)\n",
    "        o_val = [row[-1] for row in neighbors]\n",
    "        l_predictions.append(max(set(o_val), key=o_val.count))\n",
    "    return l_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0135e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With <function cartesian_distance at 0x7fd7c0723b80> and predicted labels are: ['W', 'W', 'W', 'W']\n",
      "With <function cartesian_distance at 0x7fd7c0723b80> and predicted labels are: ['W', 'M', 'W', 'W']\n",
      "With <function cartesian_distance at 0x7fd7c0723b80> and predicted labels are: ['W', 'M', 'W', 'W']\n",
      "With <function manhattan_distance at 0x7fd7a051b040> and predicted labels are: ['W', 'W', 'W', 'W']\n",
      "With <function manhattan_distance at 0x7fd7a051b040> and predicted labels are: ['W', 'M', 'W', 'W']\n",
      "With <function manhattan_distance at 0x7fd7a051b040> and predicted labels are: ['W', 'M', 'W', 'W']\n",
      "With <function minkowski_distance at 0x7fd7903f38b0> and predicted labels are: ['W', 'W', 'W', 'W']\n",
      "With <function minkowski_distance at 0x7fd7903f38b0> and predicted labels are: ['W', 'M', 'W', 'W']\n",
      "With <function minkowski_distance at 0x7fd7903f38b0> and predicted labels are: ['W', 'M', 'W', 'W']\n"
     ]
    }
   ],
   "source": [
    "# Predictions on the test data\n",
    "for dist_type in [cartesian_distance, manhattan_distance, minkowski_distance]:\n",
    "    for num_neighbors in [1, 3, 7]:\n",
    "        print(f\"With {dist_type} and predicted labels are: {predict(data_train, data_test, num_neighbors, dist_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce7cfc",
   "metadata": {},
   "source": [
    "# Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "15d52bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Leave-One-Out Evaluation function\n",
    "def leave_one_out_evaluation(data, K):\n",
    "    l_predictions = []\n",
    "    for i in range(len(data)):\n",
    "        data_test = [data[i]]\n",
    "        data_train = np.delete(data, i, axis=0)\n",
    "        l_predictions.append(predict(data_train, data_test, K, cartesian_distance))\n",
    "    l_predictions = np.array(l_predictions, dtype=object)\n",
    "    \n",
    "    temp = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == l_predictions[i]:\n",
    "            temp+=1\n",
    "    \n",
    "    return temp/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ca0c1cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K= 1, accuracy= 55.0%\n",
      "For K= 3, accuracy= 61.67%\n",
      "For K= 5, accuracy= 61.67%\n",
      "For K= 7, accuracy= 60.83%\n",
      "For K= 9, accuracy= 63.33%\n",
      "For K= 11, accuracy= 59.17%\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of the KNN algorithm (with cartesian distance) with the given values of K\n",
    "for k_val in [1, 3, 5, 7, 9, 11]:\n",
    "    print(f\"For K= {k_val}, Accuracy: {round(leave_one_out_evaluation(data_large, k_val)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b9bcb",
   "metadata": {},
   "source": [
    "# Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "769ccc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K= 1, accuracy= 62.5%\n",
      "For K= 3, accuracy= 70.83%\n",
      "For K= 5, accuracy= 65.0%\n",
      "For K= 7, accuracy= 63.33%\n",
      "For K= 9, accuracy= 60.0%\n",
      "For K= 11, accuracy= 57.5%\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of the KNN algorithm (with cartesian distance) with the given values of K, after removing the feature 'age'\n",
    "n_data_large = np.delete(data_large, 2, axis=1)\n",
    "\n",
    "for K in [1, 3, 5, 7, 9, 11]:\n",
    "    print(f\"For K= {K}, Accuracy: {round(leave_one_out_evaluation(n_data_large, K)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced91848",
   "metadata": {},
   "source": [
    "# Comparing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f9da6",
   "metadata": {},
   "source": [
    "Dropped the 'age' data and again evaluated the performance of the algorithm using Leave One Out Evaluation. I observed that the minimum, average, and maximum accuracies for all values of k utilizing all similarities reduced when the age was removed from the dataset. This brings us to the conclusion that in this situation, age is a crucial component to predict the label. The age is not the most crucial feature, but it is one that definitely helps the predictions because the decrease is not very significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
